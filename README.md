# big-data-gcw

Big Data &amp; Analytics Group Coursework

# Getting started (Goals)

1. Download the [dataset](https://www.kaggle.com/eliasdabbas/web-server-access-logs?select=access.log)
2. Normalize the dataset using `normalize.py`
3. Load it to ambari/hive-view and play with it.

# Running the script

1. Install python `3.5` or above
2. Execute it! `python3 normalize.py /Users/yasin/Downloads/access.log 20000`
3. All the cleaned data will be in `$HOME/bda-cw-workdir`

# Appendix

1. [How to move large files via terminal](https://www.cloudera.com/tutorials/manage-files-on-hdfs-via-cli-ambari-files-view/1.html)
